{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a564649",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Core Principles\n",
    "\n",
    "1. **Zero Config** ðŸš€\n",
    "   - Works immediately with built-in components\n",
    "   - No setup required to start learning\n",
    "\n",
    "2. **Registries as Mappings** ðŸ“¦\n",
    "   - Component registries are just dicts\n",
    "   - Easy to discover, access, and extend\n",
    "\n",
    "3. **Mall Pattern** ðŸ¬\n",
    "   - Separate stores for each data type\n",
    "   - Automatic persistence\n",
    "   - MutableMapping interface everywhere\n",
    "\n",
    "4. **Declarative Pipelines** âš¡\n",
    "   - Compose components by name\n",
    "   - DAG-based execution\n",
    "   - Intermediate results collected automatically\n",
    "\n",
    "5. **Progressive Enhancement** ðŸ”§\n",
    "   - Start with toys, add power as needed\n",
    "   - Plugin system for production components\n",
    "   - Optional dependencies\n",
    "\n",
    "### Design Philosophy\n",
    "\n",
    "`ef` follows these principles:\n",
    "- **SSOT** (Single Source of Truth) - One place to store each piece of data\n",
    "- **Open-Closed** - Easy to extend, hard to break\n",
    "- **Dependency Injection** - Pass components in, don't hardcode\n",
    "- **Facades** - Clean interfaces over complex functionality\n",
    "\n",
    "### When to Use `ef`\n",
    "\n",
    "âœ… **Good for:**\n",
    "- Learning about embedding pipelines\n",
    "- Prototyping ML workflows\n",
    "- Building reproducible experiments\n",
    "- When you need automatic persistence\n",
    "- When you want composable components\n",
    "\n",
    "âš ï¸ **Consider alternatives when:**\n",
    "- You need production-ready ML from the start (use imbed directly)\n",
    "- You're building a full ML platform (use MLflow, Kubeflow)\n",
    "- You need real-time streaming (ef is batch-oriented)\n",
    "\n",
    "---\n",
    "\n",
    "## Thanks for exploring `ef`! ðŸŽ‰\n",
    "\n",
    "Questions? Check out:\n",
    "- ðŸ“– [README.md](../README.md)\n",
    "- ðŸ§ª [tests/test_basic.py](../ef/tests/test_basic.py)\n",
    "- ðŸ“ [examples.py](../examples.py)\n",
    "- ðŸ”Œ [Plugin Guide](../ef/plugins/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555aba9",
   "metadata": {},
   "source": [
    "## 10. Working with File-Based Storage\n",
    "\n",
    "To try things out you can use `backend='memory'`. \n",
    "But for real projects, use files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045eac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "from ef import Project\n",
    "\n",
    "# Create a project with file-based storage\n",
    "tmpdir = tempfile.mkdtemp()\n",
    "print(f\"{tmpdir=}\")\n",
    "project = Project.create('persistent_project', root_dir=tmpdir, backend='files')\n",
    "\n",
    "# Add data and run pipeline\n",
    "project.add_source('test_doc', 'This will be saved to disk')\n",
    "_ = project.create_pipeline('simple', embedder='simple')\n",
    "results = project.run_pipeline('simple')\n",
    "\n",
    "# Check what got created\n",
    "print(\"ðŸ’¾ File-based storage created:\")\n",
    "for root, dirs, files in os.walk(tmpdir):\n",
    "    level = root.replace(tmpdir, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:5]:  # Show first 5 files\n",
    "        print(f\"{subindent}{file}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"{subindent}... and {len(files) - 5} more\")\n",
    "\n",
    "print(\"\\nðŸ’¡ With files backend:\")\n",
    "print(\"   - Data persists between sessions\")\n",
    "print(\"   - Different serialization for different data types\")\n",
    "print(\"   - segments â†’ .txt files\")\n",
    "print(\"   - embeddings â†’ .pkl files (pickle)\")\n",
    "print(\"   - planar_embeddings â†’ .json files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063df9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Multiple pipelines created:\n",
      "  1. simple\n",
      "  2. just_embed\n",
      "  3. embed_and_cluster\n",
      "  4. full_viz\n",
      "\n",
      "ðŸ’¡ Each pipeline can use different components and parameters!\n",
      "   Run whichever one fits your current needs.\n"
     ]
    }
   ],
   "source": [
    "# Create different pipelines for different tasks\n",
    "_ = project.create_pipeline('just_embed', embedder='simple')\n",
    "_ = project.create_pipeline('embed_and_cluster', embedder='char_counts', clusterer='simple_kmeans', n_clusters=3)\n",
    "_ = project.create_pipeline('full_viz', embedder='simple', planarizer='simple_2d', clusterer='threshold')\n",
    "\n",
    "print(\"ðŸ”„ Multiple pipelines created:\")\n",
    "for i, pipeline_name in enumerate(project.list_pipelines(), 1):\n",
    "    print(f\"  {i}. {pipeline_name}\")\n",
    "    \n",
    "print(\"\\nðŸ’¡ Each pipeline can use different components and parameters!\")\n",
    "print(\"   Run whichever one fits your current needs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af7350",
   "metadata": {},
   "source": [
    "## 9. Advanced: Multiple Pipelines\n",
    "\n",
    "You can create multiple pipelines for different purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca42c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ PROJECT SUMMARY\n",
      "============================================================\n",
      "Project ID        : persistent_project\n",
      "Segments          : 1\n",
      "Embeddings        : 1\n",
      "Planar Embeddings : 0\n",
      "Clusters          : 0\n",
      "Pipelines         : 4\n",
      "\n",
      "Available Components:\n",
      "  segmenters           : 3 (identity, lines, sentences)\n",
      "  embedders            : 2 (simple, char_counts)\n",
      "  planarizers          : 2 (simple_2d, normalize_2d)\n",
      "  clusterers           : 2 (simple_kmeans, threshold)\n"
     ]
    }
   ],
   "source": [
    "# Get comprehensive project summary\n",
    "summary = project.summary()\n",
    "\n",
    "print(\"ðŸ“‹ PROJECT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Project ID        : {summary['project_id']}\")\n",
    "print(f\"Segments          : {summary['n_segments']}\")\n",
    "print(f\"Embeddings        : {summary['n_embeddings']}\")\n",
    "print(f\"Planar Embeddings : {summary['n_planar_embeddings']}\")\n",
    "print(f\"Clusters          : {summary['n_clusters']}\")\n",
    "print(f\"Pipelines         : {summary['n_pipelines']}\")\n",
    "print()\n",
    "print(\"Available Components:\")\n",
    "for comp_type, names in summary['available_components'].items():\n",
    "    print(f\"  {comp_type:20} : {len(names)} ({', '.join(names[:3])}{', ...' if len(names) > 3 else ''})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f835b8",
   "metadata": {},
   "source": [
    "## 8. Project Summary - What Have We Built?\n",
    "\n",
    "Let's see everything we've created:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a831c",
   "metadata": {},
   "source": [
    "### Component Registration\n",
    "\n",
    "The `@register` decorator:\n",
    "- Adds your function to the registry\n",
    "- Stores metadata (like `dimension`)\n",
    "- Makes it available for pipelines\n",
    "- Validates the signature\n",
    "\n",
    "You can register ANY callable - functions, lambdas, class methods, etc!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c1b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our custom embedder\n",
    "_ = project.create_pipeline('word_analysis', embedder='word_stats')\n",
    "custom_results = project.run_pipeline('word_analysis')\n",
    "\n",
    "print(\"ðŸ“Š Custom embedder results:\")\n",
    "print(\"   [words, avg_length, unique_words, sentences]\")\n",
    "for key, vector in list(custom_results['embeddings'].items())[:3]:\n",
    "    print(f\"  {key:12} : {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a custom embedder using a decorator\n",
    "@project.embedders.register('word_stats', dimension=4)\n",
    "def word_statistics_embedder(segments):\n",
    "    \"\"\"\n",
    "    Create a 4D embedding: [word_count, avg_word_length, unique_words, sentence_count]\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    for key, text in segments.items():\n",
    "        words = text.split()\n",
    "        embeddings[key] = [\n",
    "            float(len(words)),                              # Total words\n",
    "            sum(len(w) for w in words) / len(words) if words else 0,  # Avg word length\n",
    "            float(len(set(words))),                         # Unique words\n",
    "            float(text.count('.') + text.count('!') + text.count('?'))  # Sentences\n",
    "        ]\n",
    "    return embeddings\n",
    "\n",
    "print(\"âœ… Custom embedder 'word_stats' registered!\")\n",
    "print(f\"   Available embedders now: {', '.join(project.embedders.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c889cf3",
   "metadata": {},
   "source": [
    "## 7. Custom Components - Extend ef\n",
    "\n",
    "You can easily add your own components! Let's create a custom embedder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86469a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick one-off embedding (doesn't persist)\n",
    "test_text = \"This is a quick test of the embedding system\"\n",
    "embeddings = project.quick_embed(test_text, embedder='simple')\n",
    "\n",
    "print(\"âš¡ Quick embed (no pipeline needed!):\")\n",
    "print(f\"  Input: '{test_text}'\")\n",
    "print(f\"  Output: {embeddings['main']}\")\n",
    "print(f\"\\nðŸ’¡ This didn't persist - check: 'main' in project.embeddings = {'main' in project.embeddings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc4c53f",
   "metadata": {},
   "source": [
    "## 6. Quick Embed - One-Off Operations\n",
    "\n",
    "Sometimes you don't need a full pipeline - just a quick embedding. Use `quick_embed()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a43e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at cluster assignments\n",
    "print(\"ðŸŽ¯ Cluster assignments:\")\n",
    "for key, cluster_id in project.clusters.items():\n",
    "    doc_preview = project.segments[key][:40] + \"...\"\n",
    "    print(f\"  Cluster {cluster_id}: {key:12} â†’ {doc_preview}\")\n",
    "    \n",
    "print(\"\\nðŸ’¡ Documents in the same cluster are considered similar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57631d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at 2D coordinates (for visualization)\n",
    "print(\"ðŸ—ºï¸  Planar embeddings (2D coordinates):\")\n",
    "for key, coords in project.planar_embeddings.items():\n",
    "    print(f\"  {key}: ({coords[0]:.3f}, {coords[1]:.3f})\")\n",
    "    \n",
    "print(\"\\nðŸ’¡ These 2D points could be plotted on a scatter plot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at embeddings (26D letter frequency vectors)\n",
    "print(\"ðŸ”¢ Embeddings (first 10 dimensions):\")\n",
    "for key, vector in list(project.embeddings.items())[:3]:\n",
    "    print(f\"  {key}: {vector[:10]}...\")\n",
    "    \n",
    "print(f\"\\nðŸ“ Each embedding has {len(list(project.embeddings.values())[0])} dimensions (a-z letter counts)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1861f",
   "metadata": {},
   "source": [
    "## 5. Explore the Results\n",
    "\n",
    "Let's examine what the pipeline produced:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72040498",
   "metadata": {},
   "source": [
    "### Pipeline Execution Explained\n",
    "\n",
    "When you run a pipeline, ef:\n",
    "1. **Loads** the data from `project.segments`\n",
    "2. **Executes** each component in sequence (DAG-based execution)\n",
    "3. **Collects** all intermediate results\n",
    "4. **Persists** everything back to the mall automatically\n",
    "\n",
    "The `results` dict contains ALL intermediate outputs - perfect for debugging and inspection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline!\n",
    "results = project.run_pipeline('full_analysis')\n",
    "\n",
    "print(\"âœ… Pipeline executed!\")\n",
    "print(f\"\\nðŸ“Š Results contain {len(results)} stages:\")\n",
    "for stage, data in results.items():\n",
    "    print(f\"  {stage:20} : {len(data)} items\")\n",
    "    \n",
    "print(\"\\nðŸ’¾ All results automatically persisted to the mall!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d04ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a full pipeline\n",
    "_ = project.create_pipeline(\n",
    "    'full_analysis',\n",
    "    embedder='char_counts',      # Convert text to 26D vectors (letter frequencies)\n",
    "    planarizer='normalize_2d',   # Reduce to 2D coordinates\n",
    "    clusterer='simple_kmeans',   # Group into clusters\n",
    "    n_clusters=2                 # Make 2 clusters\n",
    ")\n",
    "\n",
    "print(\"âœ… Pipeline 'full_analysis' created!\")\n",
    "print(\"   Steps: segments â†’ embeddings â†’ planar_embeddings â†’ clusters\")\n",
    "print(f\"   Available pipelines: {', '.join(project.list_pipelines())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a7717e",
   "metadata": {},
   "source": [
    "## 4. Create and Run a Pipeline\n",
    "\n",
    "Now for the magic! âœ¨ Let's create a pipeline that:\n",
    "1. Takes our documents (already segmented)\n",
    "2. Embeds them into vectors\n",
    "3. Reduces to 2D for visualization\n",
    "4. Clusters similar documents together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde2c0fc",
   "metadata": {},
   "source": [
    "### The Mall Pattern ðŸ¬\n",
    "\n",
    "Notice how we accessed `project.segments`? This is part of the **mall pattern**.\n",
    "\n",
    "A \"mall\" is a **store of stores** - separate storage for each data type:\n",
    "- `project.segments` - Original/segmented text\n",
    "- `project.embeddings` - Vector representations\n",
    "- `project.planar_embeddings` - 2D coordinates\n",
    "- `project.clusters` - Cluster assignments\n",
    "\n",
    "Each store is a **MutableMapping** (dict-like), so you can:\n",
    "- Get/set items: `project.embeddings['doc1'] = [1.0, 2.0]`\n",
    "- Iterate: `for key, value in project.embeddings.items(): ...`\n",
    "- Check membership: `if 'doc1' in project.embeddings: ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add multiple documents\n",
    "documents = {\n",
    "    'ai_intro': 'Artificial intelligence is transforming industries worldwide.',\n",
    "    'ml_basics': 'Machine learning models learn patterns from data.',\n",
    "    'dl_neural': 'Deep learning uses neural networks with many layers.',\n",
    "    'nlp_text': 'Natural language processing helps computers understand human language.',\n",
    "}\n",
    "\n",
    "for key, text in documents.items():\n",
    "    project.add_source(key, text)\n",
    "    \n",
    "print(f\"âœ… Added {len(documents)} documents\")\n",
    "print(f\"ðŸ“ Total segments in store: {len(project.segments)}\")\n",
    "\n",
    "# Let's peek at what's stored\n",
    "print(\"\\nðŸ“‚ Stored documents:\")\n",
    "for key in list(project.segments.keys())[:3]:\n",
    "    preview = project.segments[key][:50] + \"...\" if len(project.segments[key]) > 50 else project.segments[key]\n",
    "    print(f\"  {key}: {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8b95b",
   "metadata": {},
   "source": [
    "## 3. Add Source Data\n",
    "\n",
    "Now let's add some actual data to process. We'll use a few documents about AI/ML topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca740edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a component directly (like a dict!)\n",
    "simple_embedder = project.embedders['simple']\n",
    "\n",
    "# Use it manually\n",
    "test_segments = {\n",
    "    'text1': 'Hello world',\n",
    "    'text2': 'Machine learning is amazing!'\n",
    "}\n",
    "\n",
    "embeddings = simple_embedder(test_segments)\n",
    "\n",
    "print(\"ðŸ”¢ Embeddings from 'simple' embedder:\")\n",
    "for key, vector in embeddings.items():\n",
    "    print(f\"  {key}: {vector}\")\n",
    "    \n",
    "print(\"\\nðŸ’¡ The 'simple' embedder counts: [chars, words, punctuation]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b7044",
   "metadata": {},
   "source": [
    "### Understanding Component Types\n",
    "\n",
    "- **Segmenters**: Split text into chunks (lines, sentences, etc.)\n",
    "- **Embedders**: Convert text to vectors (numerical representations)\n",
    "- **Planarizers**: Reduce high-dimensional vectors to 2D (for visualization)\n",
    "- **Clusterers**: Group similar items together\n",
    "\n",
    "Let's see how an embedder actually works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e983ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ef (Embedding Flow) - Interactive Demo\n",
    "\n",
    "Welcome to **ef**, a lightweight framework for building embedding pipelines!\n",
    "\n",
    "## What is ef?\n",
    "\n",
    "ef makes it easy to:\n",
    "- ðŸ”„ Transform data through embedding pipelines\n",
    "- ðŸ“¦ Store and retrieve results automatically\n",
    "- ðŸ”Œ Compose components into workflows\n",
    "- ðŸŽ¯ Work immediately with built-in components\n",
    "- ðŸ”§ Extend with plugins when you need more power\n",
    "\n",
    "## Why ef?\n",
    "\n",
    "Traditional embedding workflows often require:\n",
    "- Complex setup and configuration\n",
    "- Manual data persistence\n",
    "- Hardcoded pipeline steps\n",
    "- Heavy dependencies upfront\n",
    "\n",
    "**ef solves this** by providing:\n",
    "- Zero-config startup (works immediately!)\n",
    "- Automatic persistence via the \"mall\" pattern\n",
    "- Declarative pipeline composition\n",
    "- Progressive enhancement (start simple, add power as needed)\n",
    "\n",
    "Let's dive in! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c527ab",
   "metadata": {},
   "source": [
    "## Getting Started - Create Your First Project\n",
    "\n",
    "A **Project** is your main workspace. It contains:\n",
    "- ðŸ“‹ **Component registries** - collections of functions for each pipeline stage\n",
    "- ðŸ’¾ **Data stores** - persistent storage for your data (the \"mall\")\n",
    "- âš¡ **Pipelines** - composed workflows from your components\n",
    "\n",
    "Let's create one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be92635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ef import Project\n",
    "\n",
    "# Create a project with in-memory storage (perfect for demos!)\n",
    "project = Project.create('demo_project', backend='memory')\n",
    "\n",
    "print(\"âœ… Project created!\")\n",
    "print(f\"Project ID: {project.project_id}\")\n",
    "print(f\"Storage backend: memory (nothing written to disk)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126179e0",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "When you create a project, ef automatically:\n",
    "1. Sets up **component registries** (segmenters, embedders, planarizers, clusterers)\n",
    "2. Registers **built-in toy components** so you can start immediately\n",
    "3. Creates a **mall** (store of stores) for persisting data\n",
    "\n",
    "The `backend='memory'` means everything stays in RAM - perfect for demos and testing!\n",
    "\n",
    "For production, you'd use `backend='files'` to persist to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78aa925",
   "metadata": {},
   "source": [
    "## Discover Available Components\n",
    "\n",
    "Component registries work like **dictionaries** - you can list, access, and register components.\n",
    "\n",
    "Let's see what's available out of the box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ede59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available components\n",
    "components = project.list_components()\n",
    "\n",
    "print(\"ðŸ“¦ Available Components:\\n\")\n",
    "for component_type, names in components.items():\n",
    "    print(f\"  {component_type:20} : {', '.join(names)}\")\n",
    "    \n",
    "print(\"\\nðŸ’¡ These are lightweight 'toy' implementations - perfect for learning!\")\n",
    "print(\"   (You can add production components via plugins later)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680fd24",
   "metadata": {},
   "source": [
    "## Next Steps - Production Use\n",
    "\n",
    "### Built-in vs Production Components\n",
    "\n",
    "The built-in components are **toy implementations** designed for learning and testing:\n",
    "- `simple` embedder: Just counts characters, words, punctuation\n",
    "- `char_counts` embedder: Letter frequency (26D)\n",
    "- `simple_kmeans`: Basic clustering\n",
    "- etc.\n",
    "\n",
    "### Adding Production Components\n",
    "\n",
    "For real applications, add the **imbed** plugin:\n",
    "\n",
    "```python\n",
    "from ef.plugins import imbed\n",
    "\n",
    "# This would register production components:\n",
    "# - OpenAI embeddings\n",
    "# - Sentence transformers\n",
    "# - Cohere embeddings\n",
    "# - Advanced clustering algorithms\n",
    "# - etc.\n",
    "\n",
    "imbed.register(project)\n",
    "```\n",
    "\n",
    "### Install Full Dependencies\n",
    "\n",
    "```bash\n",
    "# Get everything\n",
    "pip install ef[full]\n",
    "\n",
    "# Get imbed integration\n",
    "pip install ef[imbed]\n",
    "```\n",
    "\n",
    "### Other Extensions\n",
    "\n",
    "- **dol**: Advanced storage backends (S3, Google Cloud, databases)\n",
    "- **meshed**: Advanced DAG composition with caching\n",
    "- **larder**: Automatic result caching and memoization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310da3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
